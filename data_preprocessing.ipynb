{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef725fc1",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff6612",
   "metadata": {},
   "source": [
    "## 0. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3241d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jefit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jefit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jefit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jefit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jefit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jefit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Download NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530d939",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3fae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed lowercase datasets, one for training and the testing one for predictions. \n",
    "df_training = pd.read_csv(r'C:\\Users\\jefit\\OneDrive\\Escritorio\\Ironhack\\Ironhack candela\\Week 4\\Project\\Project-2-NLP-Challenge_Group3\\data\\training_data_lowercase.csv', header=None, names=['raw'])\n",
    "\n",
    "df_testing = pd.read_csv(r'C:\\Users\\jefit\\OneDrive\\Escritorio\\Ironhack\\Ironhack candela\\Week 4\\Project\\Project-2-NLP-Challenge_Group3\\data\\testing_data_lowercase_nolabels.csv', header=None, names=['raw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23626cd7",
   "metadata": {},
   "source": [
    "# 2. Visualize the imported dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d21b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç First 5 rows:\n",
      "                                                 raw\n",
      "0  0\\tdonald trump sends out embarrassing new yea...\n",
      "1  0\\tdrunk bragging trump staffer started russia...\n",
      "2  0\\tsheriff david clarke becomes an internet jo...\n",
      "3  0\\ttrump is so obsessed he even has obama‚Äös na...\n",
      "4  0\\tpope francis just called out donald trump d...\n",
      "\n",
      "üìã Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34152 entries, 0 to 34151\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   raw     34152 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 266.9+ KB\n",
      "None\n",
      "\n",
      "üìä Summary Statistics:\n",
      "                                                      raw\n",
      "count                                               34152\n",
      "unique                                              32206\n",
      "top     1\\tfactbox: trump fills top jobs for his admin...\n",
      "freq                                                   14\n",
      "\n",
      "üß© Missing Values:\n",
      "raw    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34152, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows\n",
    "print(\"üîç First 5 rows:\")\n",
    "print(df_training.head())\n",
    "\n",
    "# Check basic info about datatypes and non-null values\n",
    "print(\"\\nüìã Dataset Info:\")\n",
    "print(df_training.info())\n",
    "\n",
    "# Summary statistics for numerical and object columns\n",
    "print(\"\\nüìä Summary Statistics:\")\n",
    "print(df_training.describe(include='all'))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüß© Missing Values:\")\n",
    "print(df_training.isnull().sum())\n",
    "\n",
    "df_training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7fd496",
   "metadata": {},
   "source": [
    "As we can see, the imported dataset only contains one column and 34,152 rows. It seems that the label and headline columns don't exist yet, so we'll have to create them and split the existing column into two ,to differentiate between the two. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dcc6df",
   "metadata": {},
   "source": [
    "# 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb94d04",
   "metadata": {},
   "source": [
    "### 3.1 Split data into 'label' and 'headline' columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d1dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the 'raw' column into 'label' and 'headline'. By defining a function, we can easily apply it to both training and testing datasets.\n",
    "\n",
    "def split_label_headline(df, col='raw', drop_raw=True):\n",
    "    \"\"\"\n",
    "    Splits a column into 'label' and 'headline' using tab as separator.\n",
    "    Handles BOM and whitespace in label.\n",
    "    \"\"\"\n",
    "    split_cols = df[col].str.split('\\t', n=1, expand=True)\n",
    "    if split_cols.shape[1] == 1:\n",
    "        split_cols[1] = ''\n",
    "    split_cols.columns = ['label', 'headline']\n",
    "    split_cols['headline'] = split_cols['headline'].fillna('')\n",
    "    # Remove BOM and whitespace from label\n",
    "    split_cols['label'] = split_cols['label'].str.replace('\\ufeff', '', regex=False).str.strip()\n",
    "    df[['label', 'headline']] = split_cols\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    if drop_raw:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply to your datasets\n",
    "df_training = split_label_headline(df_training)\n",
    "df_testing = split_label_headline(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4905c9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34152, 2), (9984, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape, df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37693231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                           headline\n",
      "0      0  donald trump sends out embarrassing new year‚Äös...\n",
      "1      0  drunk bragging trump staffer started russian c...\n",
      "2      0  sheriff david clarke becomes an internet joke ...\n",
      "3      0  trump is so obsessed he even has obama‚Äös name ...\n",
      "4      0  pope francis just called out donald trump duri...\n",
      "   label                                           headline\n",
      "0      2  copycat muslim terrorist arrested with assault...\n",
      "1      2  wow! chicago protester caught on camera admits...\n",
      "2      2   germany's fdp look to fill schaeuble's big shoes\n",
      "3      2  mi school sends welcome back packet warning ki...\n",
      "4      2  u.n. seeks 'massive' aid boost amid rohingya '...\n"
     ]
    }
   ],
   "source": [
    "print(df_training.head())\n",
    "\n",
    "print(df_testing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ef51b",
   "metadata": {},
   "source": [
    "### 3.2 Removing duplicate & missing values from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8eb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, col='headline', label_col='label'):\n",
    "    \"\"\"\n",
    "    Removes rows with missing or empty values in the column 'headline'\n",
    "    and drops duplicate rows based on both label and headline columns.\n",
    "    \"\"\"\n",
    "    df = df[df[col].notnull() & (df[col].str.strip() != '')]\n",
    "    df = df.drop_duplicates(subset=[label_col, col])\n",
    "    return df\n",
    "\n",
    "# Only applied to the training dataset, because we don't want duplicates or missing values to affect our training process.\n",
    "df_training = clean_dataframe(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8db71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32206, 2), (9984, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape, df_testing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0555b",
   "metadata": {},
   "source": [
    "### 3.3 Removing unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d1ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headline(text):\n",
    "    \"\"\"\n",
    "    Removes unwanted characters from text, keeping only letters, spaces, apostrophes, and hyphens.\n",
    "    Also removes extra spaces.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Remove unwanted characters except letters, numbers, spaces, apostrophes, and hyphens\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s'-]\", '', text)\n",
    "    # Replace multiple spaces/newlines/tabs with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove spaces at the beginning and end\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df_training['headline'] = df_training['headline'].apply(clean_headline)\n",
    "df_testing['headline'] = df_testing['headline'].apply(clean_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b58ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends out embarrassing new years ...\n",
      "1        drunk bragging trump staffer started russian c...\n",
      "2        sheriff david clarke becomes an internet joke ...\n",
      "3        trump is so obsessed he even has obamas name c...\n",
      "4        pope francis just called out donald trump duri...\n",
      "                               ...                        \n",
      "34147    tears in rain as thais gather for late king's ...\n",
      "34148    pyongyang university needs non-us teachers as ...\n",
      "34149    philippine president duterte to visit japan ah...\n",
      "34150    japan's abe may have won election but many don...\n",
      "34151    demoralized and divided inside catalonia's pol...\n",
      "Name: headline, Length: 32206, dtype: object\n",
      "0       copycat muslim terrorist arrested with assault...\n",
      "1       wow chicago protester caught on camera admits ...\n",
      "2        germany's fdp look to fill schaeuble's big shoes\n",
      "3       mi school sends welcome back packet warning ki...\n",
      "4       un seeks 'massive' aid boost amid rohingya 'em...\n",
      "                              ...                        \n",
      "9979    boom fox news leftist chris wallace attempts t...\n",
      "9980    here it is list of democrat hypocrites who vot...\n",
      "9981    new fires ravage rohingya villages in northwes...\n",
      "9982    meals on wheels shuts the lyin lefties up with...\n",
      "9983    brilliant tucker carlson and ayaan hirsi ali d...\n",
      "Name: headline, Length: 9984, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_training['headline'])\n",
    "\n",
    "print(df_testing['headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9f452",
   "metadata": {},
   "source": [
    "### 3.3 Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d0eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_headlines(df, col='headline', new_col='tokens'):\n",
    "    \"\"\"\n",
    "    Tokenizes the values in 'headline' column and stores the result in a new column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[col].apply(word_tokenize)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_training = tokenize_headlines(df_training)\n",
    "df_testing = tokenize_headlines(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163644e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32206, 3), (9984, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape, df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31c674d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label                                           headline  \\\n",
       " 0      0  donald trump sends out embarrassing new years ...   \n",
       " 1      0  drunk bragging trump staffer started russian c...   \n",
       " 2      0  sheriff david clarke becomes an internet joke ...   \n",
       " 3      0  trump is so obsessed he even has obamas name c...   \n",
       " 4      0  pope francis just called out donald trump duri...   \n",
       " \n",
       "                                               tokens  \n",
       " 0  [donald, trump, sends, out, embarrassing, new,...  \n",
       " 1  [drunk, bragging, trump, staffer, started, rus...  \n",
       " 2  [sheriff, david, clarke, becomes, an, internet...  \n",
       " 3  [trump, is, so, obsessed, he, even, has, obama...  \n",
       " 4  [pope, francis, just, called, out, donald, tru...  ,\n",
       "    label                                           headline  \\\n",
       " 0      2  copycat muslim terrorist arrested with assault...   \n",
       " 1      2  wow chicago protester caught on camera admits ...   \n",
       " 2      2   germany's fdp look to fill schaeuble's big shoes   \n",
       " 3      2  mi school sends welcome back packet warning ki...   \n",
       " 4      2  un seeks 'massive' aid boost amid rohingya 'em...   \n",
       " \n",
       "                                               tokens  \n",
       " 0  [copycat, muslim, terrorist, arrested, with, a...  \n",
       " 1  [wow, chicago, protester, caught, on, camera, ...  \n",
       " 2  [germany, 's, fdp, look, to, fill, schaeuble, ...  \n",
       " 3  [mi, school, sends, welcome, back, packet, war...  \n",
       " 4  [un, seeks, 'massive, ', aid, boost, amid, roh...  )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head(), df_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14fa69",
   "metadata": {},
   "source": [
    "### 3.4 Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eabbc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df, tokens_col='tokens', new_col='tokens_nostop', language='english'):\n",
    "    \"\"\"\n",
    "    Removes stopwords from the tokenized headlines and stores the result in a new column.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    df[new_col] = df[tokens_col].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_training = remove_stopwords(df_training)\n",
    "df_testing = remove_stopwords(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6595d8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32206, 4), (9984, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape, df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "796f16fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label                                           headline  \\\n",
       " 0      0  donald trump sends out embarrassing new years ...   \n",
       " 1      0  drunk bragging trump staffer started russian c...   \n",
       " 2      0  sheriff david clarke becomes an internet joke ...   \n",
       " 3      0  trump is so obsessed he even has obamas name c...   \n",
       " 4      0  pope francis just called out donald trump duri...   \n",
       " \n",
       "                                               tokens  \\\n",
       " 0  [donald, trump, sends, out, embarrassing, new,...   \n",
       " 1  [drunk, bragging, trump, staffer, started, rus...   \n",
       " 2  [sheriff, david, clarke, becomes, an, internet...   \n",
       " 3  [trump, is, so, obsessed, he, even, has, obama...   \n",
       " 4  [pope, francis, just, called, out, donald, tru...   \n",
       " \n",
       "                                        tokens_nostop  \n",
       " 0  [donald, trump, sends, embarrassing, new, year...  \n",
       " 1  [drunk, bragging, trump, staffer, started, rus...  \n",
       " 2  [sheriff, david, clarke, becomes, internet, jo...  \n",
       " 3  [trump, obsessed, even, obamas, name, coded, w...  \n",
       " 4  [pope, francis, called, donald, trump, christm...  ,\n",
       "    label                                           headline  \\\n",
       " 0      2  copycat muslim terrorist arrested with assault...   \n",
       " 1      2  wow chicago protester caught on camera admits ...   \n",
       " 2      2   germany's fdp look to fill schaeuble's big shoes   \n",
       " 3      2  mi school sends welcome back packet warning ki...   \n",
       " 4      2  un seeks 'massive' aid boost amid rohingya 'em...   \n",
       " \n",
       "                                               tokens  \\\n",
       " 0  [copycat, muslim, terrorist, arrested, with, a...   \n",
       " 1  [wow, chicago, protester, caught, on, camera, ...   \n",
       " 2  [germany, 's, fdp, look, to, fill, schaeuble, ...   \n",
       " 3  [mi, school, sends, welcome, back, packet, war...   \n",
       " 4  [un, seeks, 'massive, ', aid, boost, amid, roh...   \n",
       " \n",
       "                                        tokens_nostop  \n",
       " 0  [copycat, muslim, terrorist, arrested, assault...  \n",
       " 1  [wow, chicago, protester, caught, camera, admi...  \n",
       " 2  [germany, 's, fdp, look, fill, schaeuble, 's, ...  \n",
       " 3  [mi, school, sends, welcome, back, packet, war...  \n",
       " 4  [un, seeks, 'massive, ', aid, boost, amid, roh...  )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head(), df_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37e8c0",
   "metadata": {},
   "source": [
    "### 3.5 Apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b973d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(df, tokens_col='tokens_nostop', new_col='tokens_lemmatized'):\n",
    "    \"\"\"\n",
    "    Applies lemmatization to tokens_nostop column and stores the result in a new column.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[new_col] = df[tokens_col].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_training = lemmatize_tokens(df_training)\n",
    "df_testing = lemmatize_tokens(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e409a846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32206, 5), (9984, 5))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape, df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c4ecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label                                           headline  \\\n",
       " 0      0  donald trump sends out embarrassing new years ...   \n",
       " 1      0  drunk bragging trump staffer started russian c...   \n",
       " 2      0  sheriff david clarke becomes an internet joke ...   \n",
       " 3      0  trump is so obsessed he even has obamas name c...   \n",
       " 4      0  pope francis just called out donald trump duri...   \n",
       " \n",
       "                                               tokens  \\\n",
       " 0  [donald, trump, sends, out, embarrassing, new,...   \n",
       " 1  [drunk, bragging, trump, staffer, started, rus...   \n",
       " 2  [sheriff, david, clarke, becomes, an, internet...   \n",
       " 3  [trump, is, so, obsessed, he, even, has, obama...   \n",
       " 4  [pope, francis, just, called, out, donald, tru...   \n",
       " \n",
       "                                        tokens_nostop  \\\n",
       " 0  [donald, trump, sends, embarrassing, new, year...   \n",
       " 1  [drunk, bragging, trump, staffer, started, rus...   \n",
       " 2  [sheriff, david, clarke, becomes, internet, jo...   \n",
       " 3  [trump, obsessed, even, obamas, name, coded, w...   \n",
       " 4  [pope, francis, called, donald, trump, christm...   \n",
       " \n",
       "                                    tokens_lemmatized  \n",
       " 0  [donald, trump, sends, embarrassing, new, year...  \n",
       " 1  [drunk, bragging, trump, staffer, started, rus...  \n",
       " 2  [sheriff, david, clarke, becomes, internet, jo...  \n",
       " 3  [trump, obsessed, even, obamas, name, coded, w...  \n",
       " 4  [pope, francis, called, donald, trump, christm...  ,\n",
       "    label                                           headline  \\\n",
       " 0      2  copycat muslim terrorist arrested with assault...   \n",
       " 1      2  wow chicago protester caught on camera admits ...   \n",
       " 2      2   germany's fdp look to fill schaeuble's big shoes   \n",
       " 3      2  mi school sends welcome back packet warning ki...   \n",
       " 4      2  un seeks 'massive' aid boost amid rohingya 'em...   \n",
       " \n",
       "                                               tokens  \\\n",
       " 0  [copycat, muslim, terrorist, arrested, with, a...   \n",
       " 1  [wow, chicago, protester, caught, on, camera, ...   \n",
       " 2  [germany, 's, fdp, look, to, fill, schaeuble, ...   \n",
       " 3  [mi, school, sends, welcome, back, packet, war...   \n",
       " 4  [un, seeks, 'massive, ', aid, boost, amid, roh...   \n",
       " \n",
       "                                        tokens_nostop  \\\n",
       " 0  [copycat, muslim, terrorist, arrested, assault...   \n",
       " 1  [wow, chicago, protester, caught, camera, admi...   \n",
       " 2  [germany, 's, fdp, look, fill, schaeuble, 's, ...   \n",
       " 3  [mi, school, sends, welcome, back, packet, war...   \n",
       " 4  [un, seeks, 'massive, ', aid, boost, amid, roh...   \n",
       " \n",
       "                                    tokens_lemmatized  \n",
       " 0  [copycat, muslim, terrorist, arrested, assault...  \n",
       " 1  [wow, chicago, protester, caught, camera, admi...  \n",
       " 2  [germany, 's, fdp, look, fill, schaeuble, 's, ...  \n",
       " 3  [mi, school, sends, welcome, back, packet, war...  \n",
       " 4  [un, seek, 'massive, ', aid, boost, amid, rohi...  )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head(), df_testing.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
